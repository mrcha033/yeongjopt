# YeongjoPT Backend

YeongjoPTëŠ” FastChat ê¸°ë°˜ì˜ AI ëŒ€í™” ì‹œìŠ¤í…œìœ¼ë¡œ, OpenAI API í˜¸í™˜ ì„œë²„ì™€ Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤.

## ğŸš€ Features

- **OpenAI API í˜¸í™˜**: OpenAI ChatCompletion APIì™€ í˜¸í™˜ë˜ëŠ” REST API ì œê³µ
- **Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤**: ë¸Œë¼ìš°ì € ê¸°ë°˜ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
- **ë¶„ì‚° ì•„í‚¤í…ì²˜**: Controller-Worker êµ¬ì¡°ë¡œ í™•ì¥ì„± ì œê³µ
- **ë‹¤ì–‘í•œ ëª¨ë¸ ì§€ì›**: Hugging Face ëª¨ë¸ë“¤ì„ ì‰½ê²Œ ë¡œë“œí•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥
- **ë³´ì•ˆ**: API í‚¤ ì¸ì¦ ì§€ì› (ì„ íƒì‚¬í•­)

## ğŸ“‹ Requirements

- Python 3.8+
- CUDA ì§€ì› GPU (ê¶Œì¥)
- 8GB+ RAM (ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ ì¡°ì •)

## ğŸ›  Installation

1. **ì˜ì¡´ì„± ì„¤ì¹˜**:
```bash
pip install -r requirements.txt
```

2. **í™˜ê²½ ì„¤ì •** (ì„ íƒì‚¬í•­):
```bash
# config.pyì—ì„œ ì„¤ì • ìˆ˜ì • ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©
export MODEL_PATH="your/model/path"
export API_KEY="your-api-key"  # ì„ íƒì‚¬í•­
```

## ğŸ¯ Usage

### OpenAI API í˜¸í™˜ ì„œë²„

```bash
# Linux/Mac
./run_api.sh [model_path]

# Windows
bash run_api.sh [model_path]
```

ê¸°ë³¸ì ìœ¼ë¡œ ë‹¤ìŒ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤:
- `http://localhost:8000/v1/chat/completions` - ChatCompletion API
- `http://localhost:8000/v1/models` - ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
- `http://localhost:8000/health` - í—¬ìŠ¤ ì²´í¬

### Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤

```bash
# Linux/Mac  
./run.sh [model_path]

# Windows
bash run.sh [model_path]
```

ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:7860`ìœ¼ë¡œ ì ‘ì†

## ğŸ”§ Configuration

`config.py`ì—ì„œ ë‹¤ìŒ ì„¤ì •ë“¤ì„ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
class Settings:
    HOST: str = "0.0.0.0"
    CONTROLLER_PORT: int = 21001
    MODEL_WORKER_PORT: int = 21002
    API_PORT: int = 8000
    GRADIO_PORT: int = 7860
    
    DEFAULT_MODEL_PATH: str = "mistralai/Mistral-7B-Instruct-v0.1"
    MODEL_NAME: str = "yeongjopt-mistral-7b"
    
    API_KEY: Optional[str] = None  # API í‚¤ ì„¤ì • (ì„ íƒì‚¬í•­)
    WORKER_CONCURRENCY: int = 5
```

## ğŸŒ API Usage Examples

### Python (OpenAI í´ë¼ì´ì–¸íŠ¸)

```python
import openai

# API ì„œë²„ ì„¤ì •
openai.api_base = "http://localhost:8000/v1"
openai.api_key = "your-api-key"  # API í‚¤ë¥¼ ì„¤ì •í•œ ê²½ìš°

# ì±„íŒ… ì™„ì„±
response = openai.ChatCompletion.create(
    model="yeongjopt-mistral-7b",
    messages=[
        {"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”!"}
    ],
    temperature=0.7,
    max_tokens=512
)

print(response.choices[0].message.content)
```

### cURL

```bash
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-api-key" \
  -d '{
    "model": "yeongjopt-mistral-7b",
    "messages": [
      {"role": "user", "content": "Hello!"}
    ],
    "temperature": 0.7,
    "max_tokens": 512
  }'
```

### JavaScript/Node.js

```javascript
const response = await fetch('http://localhost:8000/v1/chat/completions', {
    method: 'POST',
    headers: {
        'Content-Type': 'application/json',
        'Authorization': 'Bearer your-api-key'
    },
    body: JSON.stringify({
        model: 'yeongjopt-mistral-7b',
        messages: [
            { role: 'user', content: 'Hello!' }
        ],
        temperature: 0.7,
        max_tokens: 512
    })
});

const data = await response.json();
console.log(data.choices[0].message.content);
```

## ğŸ³ Docker Support (ì¶”í›„ êµ¬í˜„ ì˜ˆì •)

```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8000

CMD ["bash", "run_api.sh"]
```

## ğŸ— Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client        â”‚â”€â”€â”€â”€â”‚  API Server     â”‚â”€â”€â”€â”€â”‚   Controller    â”‚
â”‚                 â”‚    â”‚  (Port 8000)    â”‚    â”‚  (Port 21001)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚  Model Worker   â”‚
                                               â”‚  (Port 21002)   â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”’ Security

- API í‚¤ ì¸ì¦ ì§€ì› (config.pyì—ì„œ `API_KEY` ì„¤ì •)
- CORS ì„¤ì • í¬í•¨
- HTTPSëŠ” ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ(nginx ë“±)ì—ì„œ ì²˜ë¦¬ ê¶Œì¥

## ğŸ“Š Monitoring

ë¡œê·¸ íŒŒì¼ë“¤ì€ `./logs/` ë””ë ‰í† ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤:
- `controller.log` - ì»¨íŠ¸ë¡¤ëŸ¬ ë¡œê·¸
- `worker.log` - ëª¨ë¸ ì›Œì»¤ ë¡œê·¸  
- `api_server.log` - API ì„œë²„ ë¡œê·¸
- `gradio.log` - Gradio ì„œë²„ ë¡œê·¸

## ğŸš¨ Troubleshooting

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

1. **ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨**:
   - GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš© ë˜ëŠ” `--load-8bit` ì˜µì…˜ ì¶”ê°€
   - ëª¨ë¸ ê²½ë¡œ í™•ì¸: ìœ íš¨í•œ Hugging Face ëª¨ë¸ ê²½ë¡œì¸ì§€ í™•ì¸

2. **í¬íŠ¸ ì¶©ëŒ**:
   - `config.py`ì—ì„œ í¬íŠ¸ ë²ˆí˜¸ ë³€ê²½
   - ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ í¬íŠ¸ ì„¤ì •

3. **API ì¸ì¦ ì˜¤ë¥˜**:
   - API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
   - `Authorization: Bearer <api-key>` í—¤ë” í™•ì¸

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [FastChat](https://github.com/lm-sys/FastChat) - ê¸°ë°˜ í”„ë ˆì„ì›Œí¬
- [Hugging Face](https://huggingface.co/) - ëª¨ë¸ í—ˆë¸Œ
- [FastAPI](https://fastapi.tiangolo.com/) - API í”„ë ˆì„ì›Œí¬ 